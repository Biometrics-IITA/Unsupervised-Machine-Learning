{
  "hash": "5cca13b697e097ce11d13856ba45d228",
  "result": {
    "engine": "knitr",
    "markdown": "---\n title: \"<p style=\\\"color:black,text-align:center\\\">Unsupervised Machine Learning </p>\" \n author:    \n  - name: <font color=#ff6600><b>Biometrics Unit</b></font>      \n    affiliation: <font color=#ff6600><b>International Institute of Tropical Agriculture (IITA)</b></font>\n---\n\n\n# [**Unsupervised Learning**]{style=\"color: #234F1E;\"}\n\nIn unsupervised learning, the algorithm is trained using a dataset without labeled outputs, meaning the input data does not come with predefined answers. The model learns to identify patterns and relationships within the data. This approach is commonly used for tasks like clustering, dimensionality reduction, and anomaly detection. As the name implies, unsupervised learning employs self-learning algorithms that operate without labels or prior training. Instead, the model is provided with raw, unlabeled data and must derive its own rules and structure by identifying similarities, differences, and patterns, without receiving explicit instructions on how to handle each data point. Unsupervised learning algorithms are particularly effective for handling complex processing tasks, such as grouping large datasets into clusters. They excel at uncovering previously hidden patterns within the data and can reveal features that are valuable for categorizing information.\n\n![](images/unsupervised.png){width=\"60%\"}\n\nSource:geeks for geeks\n\n**Examples**\n\nHere are some examples of unsupervised learning:\n\n-   **Clustering, e.g. K-means clustering**\n-   **Association, e.g. Apriori algorithm**\n-   **Dimensionality reduction, e.g. Principal Component Analysis (PCA)**\n-   **Anomaly detection, e.g. Isolation forest**\n\n## [**Clustering Use Case**]{style=\"color: #2C6D26;\"}\n\nThe `agridat` package in R contains a wealth of agricultural datasets that can be used for various statistical analyses, including clustering. Clustering is a technique that can group similar data points based on their attributes. We can use the datasets in `agridat` to demonstrate clustering techniques. Let's say we want to cluster different varieties of corn based on several agronomic traits (like yield, height, and so on) to understand which varieties are similar to each other.\n\n### **Step 1 - Install and Load Necessary Packages**\n\nMake sure you have the `agricolae` package installed along with `factoextra` package for visualization.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|eval=TRUE\n#|results='hide'\n#|echo = FALSE\nsuppressPackageStartupMessages({install.packages(\"agricolae\")  # agricolae for agricultural methods     \ninstall.packages(\"factoextra\")})  # for visualizing clustering     \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\npackage 'agricolae' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n\tC:\\Users\\DOjekere\\AppData\\Local\\Temp\\RtmpC0D2Fo\\downloaded_packages\npackage 'factoextra' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n\tC:\\Users\\DOjekere\\AppData\\Local\\Temp\\RtmpC0D2Fo\\downloaded_packages\n```\n\n\n:::\n\n```{.r .cell-code}\nsuppressMessages({library(agricolae)     \nlibrary(factoextra)}) \n```\n:::\n\n\n### **Step 2 - Load a Dataset**\n\nFor this example, we will use the `corn.yield` dataset from `agridat`. This dataset includes information on different corn varieties and their yields.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|eval=TRUE\n#|tidy=FALSE\n#|size='tiny'\n# Example data - replace with your own dataset   \ndata(iris)     \ndf <- iris[, -5]  # Exclude Species for clustering\n```\n:::\n\n\n### **Step 3 - Data Preprocessing**\n\nIt's essential to preprocess the data, such as scaling or normalizing if the features have different scales.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_scaled <- scale(df) #scale the dataset\n```\n:::\n\n\n### **Step 4 - K-means Clustering**\n\nWe can use the `k-means` clustering method and the elbow method to find the optimal number of clusters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Trying different values of k      \nset.seed(123)  # For reproducibility    \nkmeans_result <- kmeans(df_scaled, centers = 3, nstart = 25)      \n```\n:::\n\n\nUse packages like `factoextra` to visualize the clustering results.\n\n### **Step 5 - Visualizing Clusters**\n\nWe can visualize the clustering results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualizing the clustering     \nfviz_cluster(kmeans_result, data = df_scaled, geom = \"point\", ellipse.type = \"convex\") +      \n  theme_minimal() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nYou can analyze the composition of the clusters and draw conclusions based on your research questions.\n\n**Using agricolae for further analysis:**\n\nIf you want to perform multiple comparisons or ANOVA after clustering, you can integrate agricolae methods.\n\nFor example, after clustering, if you want to compare the means of different clusters, you could use:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add cluster memberships to the original dataset  \ndf$Cluster <- factor(kmeans_result$cluster)     \n# Perform ANOVA    \nanova_result <- aov(Sepal.Length ~ Cluster, data = df)    \nsummary(anova_result)     \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Df Sum Sq Mean Sq F value Pr(>F)    \nCluster       2  76.46   38.23   218.6 <2e-16 ***\nResiduals   147  25.71    0.17                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# Using Tukey's HSD test to compare means    \nHSD.test(anova_result, \"Cluster\", group = TRUE)\n```\n:::\n\n\n-   Since the p-value is extremely low, we conclude that there are significant differences between the clusters being analyzed. This typically implies that at least one of the cluster means differs from the others, warranting further investigation into the specific group differences (for example, using post-hoc tests). In summary, the ANOVA results indicate strong evidence that the clusters being compared have different means, and the differences are highly statistically significant.\n\n## [**Anomaly Detection Use Case**]{style=\"color: #2C6D26;\"}\n\nAnomaly detection in agriculture is crucial for identifying irregularities in data, such as unusual crop yields, abnormal soil conditions, or deviations in environmental variables. Here, I'll walk you through an example of anomaly detection using a synthetic dataset related to crop yields. We'll use R and the `anomalize` package, which is suitable for time series anomaly detection.\n\n**Objective**: Detect anomalies in crop yield data over time.\n\n### **Step 1 - Install and Load Required Packages**\n\nIf you haven’t installed the required packages, you can do so using the following commands:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|eval=TRUE\n#|warning=FALSE\n#|message= FALSE\n#|results='hide'\n\n  \n#install.packages(\"ggplot2\")  \n#install.packages(\"dplyr\")  \n#install.packages(\"tibble\")  \nsuppressPackageStartupMessages({install.packages(\"anomalize\")\nlibrary(anomalize)  \nlibrary(ggplot2)  \nlibrary(dplyr)  \nlibrary(tibble)})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\npackage 'anomalize' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n\tC:\\Users\\DOjekere\\AppData\\Local\\Temp\\RtmpC0D2Fo\\downloaded_packages\n```\n\n\n:::\n:::\n\n\n### **Step 2 - Create a Sample Dataset**\n\nLet's create a synthetic dataset that simulates monthly crop yields with some anomalies:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)   \n# Generate synthetic data  \ndates <- seq.Date(from = as.Date(\"2023-01-01\"),\n                  by = \"month\", length.out = 24)\nyields <- rnorm(24, mean = 50, sd = 10)  # Normal crop yields \nyields[c(5, 12, 18)] <- yields[c(5, 12, 18)] + c(20, -15, 25)  # \n```\n:::\n\n\nAdding anomalies\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a data frame  \ncrop_data <- tibble(date = dates, yield = yields) \n# Print the dataset  \nprint(crop_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 24 × 2\n   date       yield\n   <date>     <dbl>\n 1 2023-01-01  44.4\n 2 2023-02-01  47.7\n 3 2023-03-01  65.6\n 4 2023-04-01  50.7\n 5 2023-05-01  71.3\n 6 2023-06-01  67.2\n 7 2023-07-01  54.6\n 8 2023-08-01  37.3\n 9 2023-09-01  43.1\n10 2023-10-01  45.5\n# ℹ 14 more rows\n```\n\n\n:::\n:::\n\n\n### **Step 3 - Detect Anomalies**\n\nWe’ll use the `anomalize` package to detect anomalies in the crop yield data. The package provides a straightforward way to apply anomaly detection to time series data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|message=FALSE\n# Convert to time series object  \ncrop_data_ts <- crop_data %>%      \n  arrange(date) %>%     \n  as_tibble() %>%      \n  time_decompose(yield, method = \"stl\") %>%     \n  anomalize(remainder, method = \"iqr\") %>%  \n  time_recompose()   \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nConverting from tbl_df to tbl_time.\nAuto-index message: index = date\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nfrequency = 3 months\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\ntrend = 12 months\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n```\n\n\n:::\n\n```{.r .cell-code}\n# Print the anomaly results  \nprint(crop_data_ts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A time tibble: 24 × 10\n# Index:         date\n   date       observed season trend remainder remainder_l1 remainder_l2 anomaly\n   <date>        <dbl>  <dbl> <dbl>     <dbl>        <dbl>        <dbl> <chr>  \n 1 2023-01-01     44.4  4.91   44.1    -4.65         -29.9         33.2 No     \n 2 2023-02-01     47.7 -0.759  44.4     4.10         -29.9         33.2 No     \n 3 2023-03-01     65.6 -4.15   44.6    25.2          -29.9         33.2 No     \n 4 2023-04-01     50.7  4.91   44.8     0.983        -29.9         33.2 No     \n 5 2023-05-01     71.3 -0.759  45.0    27.0          -29.9         33.2 No     \n 6 2023-06-01     67.2 -4.15   45.2    26.1          -29.9         33.2 No     \n 7 2023-07-01     54.6  4.91   45.4     4.32         -29.9         33.2 No     \n 8 2023-08-01     37.3 -0.759  45.4    -7.25         -29.9         33.2 No     \n 9 2023-09-01     43.1 -4.15   45.3     1.94         -29.9         33.2 No     \n10 2023-10-01     45.5  4.91   46.0    -5.35         -29.9         33.2 No     \n# ℹ 14 more rows\n# ℹ 2 more variables: recomposed_l1 <dbl>, recomposed_l2 <dbl>\n```\n\n\n:::\n:::\n\n\n### **Step 4 - Visualize the Results**\n\nWe can visualize the detected anomalies to better understand where they occur:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the results  \nggplot(crop_data_ts, aes(x = date, y = observed)) +   \n  geom_line(color = \"blue\") +     \n  geom_point(data = subset(crop_data_ts, anomaly == \"Yes\"), \n             aes(color = anomaly), size = 3) +      \n  labs(title = \"Anomaly Detection in Crop Yields\",        \n       x = \"Date\",        \n       y = \"Observed Yield\") +   \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n**Summary**\n\n1.  **Create a Dataset**: We generated a synthetic dataset with normal crop yields and added some anomalies.\n2.  **Apply Anomaly Detection**: We used the `anomalize` package to detect anomalies in the time series data.\n3.  **Visualize Results**: We plotted the results to highlight the detected anomalies.\n\nThis example demonstrates a basic approach to anomaly detection in agricultural data. For real-world applications, you might have more complex datasets and might need to explore additional preprocessing steps or more sophisticated anomaly detection methods based on the nature of your data.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}